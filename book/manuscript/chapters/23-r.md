# Chapter 23: R - The Language of Statistics

## Introduction

R is a programming language and environment specifically designed for statistical computing and graphics. Created by Ross Ihaka and Robert Gentleman at the University of Auckland in the mid-1990s, R has become the lingua franca of statisticians, data scientists, and researchers worldwide. With its comprehensive statistical capabilities, extensive package ecosystem (CRAN), and powerful visualization tools, R excels at data analysis, machine learning, and scientific computing. While not traditionally used for web services, R's Plumber framework enables the creation of REST APIs that can expose statistical models and analyses as web services.

## About the R Programming Language

R evolved from the S language developed at Bell Laboratories in the 1970s. It was designed to make statistical analysis accessible to non-programmers while providing the flexibility needed by statisticians to develop new methods. R's strength lies not just in its built-in statistical functions, but in its vibrant community that has contributed over 19,000 packages to CRAN (Comprehensive R Archive Network), covering everything from genomics to finance.

### Language Philosophy

R embodies these principles:
- **Statistical First**: Designed specifically for data analysis
- **Vectorization**: Operations on entire vectors without explicit loops
- **Functional Programming**: Functions as first-class citizens
- **Interactive**: REPL-driven development for exploration
- **Reproducible Research**: Integration with literate programming tools
- **Open Source**: Free software with active community

## REST API Implementation with Plumber

Our R implementation uses Plumber, which allows R functions to be exposed as HTTP endpoints through special comments.

### Task Model with Reference Classes

```r
Task <- setRefClass("Task",
  fields = list(
    id = "character",
    title = "character",
    description = "character",
    status = "character",
    priority = "character",
    tags = "list",
    assigned_to = "character",
    created_at = "character",
    updated_at = "character"
  ),
  methods = list(
    initialize = function(title = "", description = "", status = "pending",
                         priority = "medium", tags = list(), assigned_to = "") {
      .self$id <<- UUIDgenerate()
      .self$title <<- title
      .self$description <<- description
      .self$status <<- status
      .self$priority <<- priority
      .self$tags <<- as.list(tags)
      .self$assigned_to <<- assigned_to
      
      current_time <- format(Sys.time(), "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
      .self$created_at <<- current_time
      .self$updated_at <<- current_time
    },
    
    update = function(updates) {
      if (!is.null(updates$title)) .self$title <<- updates$title
      if (!is.null(updates$description)) .self$description <<- updates$description
      if (!is.null(updates$status)) .self$status <<- updates$status
      if (!is.null(updates$priority)) .self$priority <<- updates$priority
      if (!is.null(updates$tags)) .self$tags <<- as.list(updates$tags)
      if (!is.null(updates$assigned_to)) .self$assigned_to <<- updates$assigned_to
      .self$updated_at <<- format(Sys.time(), "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
    },
    
    to_list = function() {
      list(
        id = .self$id,
        title = .self$title,
        description = .self$description,
        status = .self$status,
        priority = .self$priority,
        tags = .self$tags,
        assigned_to = .self$assigned_to,
        created_at = .self$created_at,
        updated_at = .self$updated_at
      )
    }
  )
)
```

### Plumber API Definition

```r
#* @apiTitle Task Management API
#* @apiDescription REST API for task management built with R and Plumber

#* Enable CORS
#* @filter cors
function(req, res) {
  res$setHeader("Access-Control-Allow-Origin", "*")
  res$setHeader("Access-Control-Allow-Methods", "GET, POST, PUT, PATCH, DELETE, OPTIONS")
  res$setHeader("Access-Control-Allow-Headers", "Content-Type")
  
  if (req$REQUEST_METHOD == "OPTIONS") {
    res$status <- 204
    return(list())
  }
  
  plumber::forward()
}

#* List all tasks
#* @param status:str Filter by status
#* @param assigned_to:str Filter by assignee
#* @param tags:str Filter by tags (comma-separated)
#* @get /api/tasks
function(status = NULL, assigned_to = NULL, tags = NULL) {
  repository$list_tasks(status, assigned_to, tags)
}

#* Create a new task
#* @post /api/tasks
function(req, res) {
  data <- req$body
  
  if (is.null(data$title) || data$title == "") {
    res$status <- 400
    return(list(error = "Title is required"))
  }
  
  task <- repository$create_task(data)
  res$status <- 201
  return(task)
}
```

## Data Structures in R

### Vectors - The Foundation

```r
# Atomic vectors
numeric_vec <- c(1.5, 2.7, 3.9)
character_vec <- c("apple", "banana", "cherry")
logical_vec <- c(TRUE, FALSE, TRUE)

# Vectorized operations
squared <- numeric_vec ^ 2
upper <- toupper(character_vec)
indices <- which(logical_vec)

# Named vectors
scores <- c(alice = 85, bob = 92, charlie = 78)
scores["alice"]  # 85
```

### Lists - Heterogeneous Collections

```r
# Lists can contain different types
person <- list(
  name = "Alice",
  age = 30,
  scores = c(85, 90, 88),
  address = list(
    street = "123 Main St",
    city = "Boston"
  )
)

# Access elements
person$name           # "Alice"
person[["age"]]      # 30
person[[3]][2]       # 90 (second score)
```

### Data Frames - Tabular Data

```r
# Create data frame
tasks_df <- data.frame(
  id = c("t1", "t2", "t3"),
  title = c("Task 1", "Task 2", "Task 3"),
  priority = factor(c("high", "low", "medium"), 
                   levels = c("low", "medium", "high")),
  completed = c(TRUE, FALSE, FALSE),
  hours = c(2.5, 1.0, 3.5)
)

# Operations
tasks_df$title                      # Extract column
tasks_df[tasks_df$priority == "high", ]  # Filter rows
tasks_df[order(tasks_df$hours), ]   # Sort
```

### Matrices and Arrays

```r
# Matrix (2D)
mat <- matrix(1:12, nrow = 3, ncol = 4)
mat[2, 3]  # Element at row 2, column 3

# Array (n-dimensional)
arr <- array(1:24, dim = c(3, 4, 2))
arr[, , 1]  # First "slice"

# Matrix operations
t(mat)      # Transpose
mat %*% t(mat)  # Matrix multiplication
```

## Functional Programming in R

### Functions as First-Class Citizens

```r
# Function definition
calculate_stats <- function(x, na.rm = TRUE) {
  list(
    mean = mean(x, na.rm = na.rm),
    median = median(x, na.rm = na.rm),
    sd = sd(x, na.rm = na.rm),
    range = range(x, na.rm = na.rm)
  )
}

# Higher-order functions
apply_to_columns <- function(df, fun) {
  lapply(df, fun)
}

# Anonymous functions
numbers <- 1:10
squares <- sapply(numbers, function(x) x^2)

# With pipe operator (magrittr)
library(magrittr)
result <- numbers %>%
  sapply(function(x) x^2) %>%
  mean()
```

### The Apply Family

```r
# lapply - returns list
list_result <- lapply(1:3, function(x) x^2)

# sapply - simplifies to vector/matrix
vector_result <- sapply(1:3, function(x) x^2)

# apply - for matrices/arrays
mat <- matrix(1:12, nrow = 3)
row_sums <- apply(mat, 1, sum)  # Sum across rows
col_means <- apply(mat, 2, mean)  # Mean across columns

# mapply - multiple arguments
mapply(function(x, y) x + y, 1:3, 4:6)

# tapply - apply by groups
data <- data.frame(
  value = c(10, 20, 15, 25, 30),
  group = c("A", "B", "A", "B", "A")
)
group_means <- tapply(data$value, data$group, mean)
```

### Closures and Environments

```r
# Closure example
create_counter <- function(initial = 0) {
  count <- initial
  
  list(
    increment = function() {
      count <<- count + 1
      count
    },
    decrement = function() {
      count <<- count - 1
      count
    },
    get = function() count,
    reset = function() {
      count <<- initial
      count
    }
  )
}

counter <- create_counter(10)
counter$increment()  # 11
counter$increment()  # 12
counter$get()       # 12
```

## Object-Oriented Programming in R

### S3 Classes (Simple)

```r
# Create S3 class
create_task <- function(title, priority = "medium") {
  structure(
    list(
      title = title,
      priority = priority,
      created_at = Sys.time()
    ),
    class = "task"
  )
}

# Generic function
print.task <- function(x, ...) {
  cat("Task:", x$title, "\n")
  cat("Priority:", x$priority, "\n")
  cat("Created:", format(x$created_at), "\n")
}

# Method dispatch
task <- create_task("Important task", "high")
print(task)  # Uses print.task
```

### S4 Classes (Formal)

```r
# Define S4 class
setClass("Task",
  slots = list(
    id = "character",
    title = "character",
    priority = "character",
    tags = "list"
  ),
  prototype = list(
    priority = "medium",
    tags = list()
  )
)

# Constructor
setMethod("initialize", "Task",
  function(.Object, title, ...) {
    .Object@id <- UUIDgenerate()
    .Object@title <- title
    callNextMethod(.Object, ...)
  }
)

# Generic method
setGeneric("prioritize", function(x) standardGeneric("prioritize"))

setMethod("prioritize", "Task",
  function(x) {
    x@priority <- "urgent"
    x
  }
)
```

### Reference Classes (R5)

```r
Repository <- setRefClass("Repository",
  fields = list(
    tasks = "list",
    last_id = "numeric"
  ),
  methods = list(
    initialize = function() {
      .self$tasks <<- list()
      .self$last_id <<- 0
    },
    
    add_task = function(title, description = "") {
      .self$last_id <<- .self$last_id + 1
      task <- list(
        id = .self$last_id,
        title = title,
        description = description
      )
      .self$tasks[[as.character(.self$last_id)]] <<- task
      invisible(task)
    },
    
    get_task = function(id) {
      .self$tasks[[as.character(id)]]
    },
    
    list_all = function() {
      .self$tasks
    }
  )
)

repo <- Repository$new()
repo$add_task("First task")
```

## Data Manipulation with tidyverse

### dplyr for Data Transformation

```r
library(dplyr)

# Sample data
tasks_df <- data.frame(
  id = 1:10,
  title = paste("Task", 1:10),
  status = sample(c("pending", "in_progress", "completed"), 10, replace = TRUE),
  priority = sample(c("low", "medium", "high"), 10, replace = TRUE),
  hours = runif(10, 1, 10)
)

# Pipeline operations
result <- tasks_df %>%
  filter(status != "completed") %>%
  mutate(
    urgency = ifelse(priority == "high", hours * 2, hours),
    deadline = Sys.Date() + days(urgency)
  ) %>%
  arrange(desc(urgency)) %>%
  select(id, title, priority, urgency, deadline) %>%
  group_by(priority) %>%
  summarise(
    count = n(),
    avg_urgency = mean(urgency),
    total_hours = sum(hours)
  )
```

### tidyr for Data Reshaping

```r
library(tidyr)

# Wide to long format
wide_data <- data.frame(
  id = 1:3,
  jan = c(100, 200, 150),
  feb = c(110, 190, 160),
  mar = c(120, 210, 155)
)

long_data <- wide_data %>%
  pivot_longer(
    cols = c(jan, feb, mar),
    names_to = "month",
    values_to = "value"
  )

# Long to wide format
wide_again <- long_data %>%
  pivot_wider(
    names_from = month,
    values_from = value
  )
```

## Statistical Computing

### Descriptive Statistics

```r
# Basic statistics
data <- rnorm(1000, mean = 100, sd = 15)

summary(data)
mean(data)
median(data)
sd(data)
var(data)
quantile(data, probs = c(0.25, 0.5, 0.75))

# Custom summary function
describe <- function(x) {
  list(
    n = length(x),
    mean = mean(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE),
    median = median(x, na.rm = TRUE),
    mad = mad(x, na.rm = TRUE),
    min = min(x, na.rm = TRUE),
    max = max(x, na.rm = TRUE),
    range = range(x, na.rm = TRUE),
    skewness = moments::skewness(x, na.rm = TRUE),
    kurtosis = moments::kurtosis(x, na.rm = TRUE)
  )
}
```

### Linear Models

```r
# Linear regression
model_data <- data.frame(
  hours_worked = runif(100, 1, 10),
  complexity = sample(1:5, 100, replace = TRUE),
  experience = runif(100, 0, 10)
)
model_data$completion_time <- 
  2 * model_data$hours_worked + 
  3 * model_data$complexity - 
  0.5 * model_data$experience + 
  rnorm(100, 0, 2)

# Fit model
lm_model <- lm(completion_time ~ hours_worked + complexity + experience, 
               data = model_data)

summary(lm_model)
coefficients(lm_model)
predict(lm_model, newdata = data.frame(
  hours_worked = 5,
  complexity = 3,
  experience = 2
))
```

### Time Series Analysis

```r
# Create time series
ts_data <- ts(rnorm(120, 100, 10), 
              start = c(2014, 1), 
              frequency = 12)

# Decomposition
decomposed <- decompose(ts_data)
plot(decomposed)

# ARIMA model
library(forecast)
arima_model <- auto.arima(ts_data)
forecast_result <- forecast(arima_model, h = 12)
plot(forecast_result)
```

## Visualization with ggplot2

### Basic Plots

```r
library(ggplot2)

# Scatter plot
ggplot(tasks_df, aes(x = hours, y = urgency, color = priority)) +
  geom_point(size = 3) +
  scale_color_manual(values = c("low" = "green", 
                               "medium" = "orange", 
                               "high" = "red")) +
  theme_minimal() +
  labs(title = "Task Urgency vs Hours",
       x = "Hours Required",
       y = "Urgency Score")

# Bar chart
ggplot(tasks_df, aes(x = status, fill = priority)) +
  geom_bar(position = "dodge") +
  theme_classic() +
  labs(title = "Tasks by Status and Priority")
```

### Advanced Visualizations

```r
# Faceted plots
ggplot(tasks_df, aes(x = hours, y = urgency)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ priority) +
  theme_bw()

# Heatmap
correlation_matrix <- cor(tasks_df[, numeric_columns])
library(reshape2)
melted_corr <- melt(correlation_matrix)

ggplot(melted_corr, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1)) +
  theme_minimal() +
  coord_fixed()
```

## Package Development

### Package Structure

```r
# Create package skeleton
package.skeleton("mypackage")

# DESCRIPTION file
Package: mypackage
Type: Package
Title: My Amazing Package
Version: 1.0.0
Author: Your Name
Maintainer: Your Name <email@example.com>
Description: A package for doing amazing things.
License: MIT
Imports:
    dplyr,
    ggplot2
Suggests:
    testthat

# NAMESPACE file
export(my_function)
importFrom(dplyr, "%>%")
```

### Documenting with roxygen2

```r
#' Calculate Task Complexity Score
#'
#' @param hours Estimated hours for the task
#' @param priority Task priority (low, medium, high)
#' @param dependencies Number of task dependencies
#' @return A numeric complexity score
#' @export
#' @examples
#' calculate_complexity(5, "high", 3)
calculate_complexity <- function(hours, priority, dependencies) {
  priority_weight <- switch(priority,
    low = 1,
    medium = 2,
    high = 3,
    1
  )
  
  hours * priority_weight + dependencies * 0.5
}
```

## Performance Optimization

### Vectorization

```r
# Slow: loop-based
slow_function <- function(n) {
  result <- numeric(n)
  for (i in 1:n) {
    result[i] <- sqrt(i) * 2
  }
  result
}

# Fast: vectorized
fast_function <- function(n) {
  sqrt(1:n) * 2
}

# Benchmark
library(microbenchmark)
microbenchmark(
  slow = slow_function(10000),
  fast = fast_function(10000),
  times = 100
)
```

### Parallel Processing

```r
library(parallel)

# Detect cores
num_cores <- detectCores() - 1

# Parallel lapply
cl <- makeCluster(num_cores)
results <- parLapply(cl, 1:100, function(x) {
  # Expensive computation
  Sys.sleep(0.1)
  x^2
})
stopCluster(cl)

# Using foreach
library(foreach)
library(doParallel)

registerDoParallel(num_cores)
results <- foreach(i = 1:100, .combine = c) %dopar% {
  # Parallel computation
  i^2
}
```

### Memory Management

```r
# Check memory usage
object.size(large_dataframe)
memory.size()
memory.limit()

# Efficient data reading
library(data.table)
dt <- fread("large_file.csv")  # Much faster than read.csv

# Remove objects and garbage collect
rm(large_object)
gc()

# Use integers when possible
df$id <- as.integer(df$id)  # Uses less memory than numeric
```

## R vs Other Languages

### R vs Python
- **R Advantages**: Superior statistical packages, better for research, tidyverse ecosystem
- **Python Advantages**: General purpose, better for production, larger web framework selection
- **Use R when**: Statistical analysis, research, academic work
- **Use Python when**: Building production systems, deep learning, web applications

### R vs Julia
- **R Advantages**: Mature ecosystem, more packages, better IDE support
- **Julia Advantages**: Better performance, designed for numerical computing
- **Use R when**: Need specific statistical packages, working with statisticians
- **Use Julia when**: Performance is critical, numerical computing focus

### R vs MATLAB
- **R Advantages**: Free and open source, larger package ecosystem
- **MATLAB Advantages**: Better engineering toolboxes, Simulink
- **Use R when**: Statistical analysis, data science, cost matters
- **Use MATLAB when**: Engineering applications, signal processing

## Best Practices

1. **Use vectorization**: Avoid loops when possible
2. **Leverage tidyverse**: Consistent, readable data manipulation
3. **Document with roxygen2**: Clear function documentation
4. **Test with testthat**: Comprehensive unit testing
5. **Profile before optimizing**: Use Rprof() to find bottlenecks
6. **Use appropriate data structures**: data.table for large datasets
7. **Follow style guide**: Use styler and lintr
8. **Version control**: Use renv for package management

## Conclusion

R demonstrates that domain-specific languages can excel by focusing on their core strength. While our REST API implementation shows R can handle web services through Plumber, the language truly shines in statistical computing, data analysis, and visualization. Its comprehensive package ecosystem, powerful data manipulation tools, and statistical capabilities make it indispensable for data scientists and researchers.

The combination of functional programming features, vectorized operations, and integrated visualization creates an environment where complex analyses can be expressed concisely and clearly. While R may not be the fastest language or the best choice for general-purpose programming, its specialized focus on statistics and data analysis makes it unmatched in its domain.

For organizations needing to expose statistical models and analyses as services, R with Plumber provides a straightforward path from research to production, allowing data scientists to deploy their work without switching languages or platforms.